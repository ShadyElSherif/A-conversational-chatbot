{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport time\nimport os\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-24T00:44:19.953032Z","iopub.execute_input":"2023-09-24T00:44:19.953617Z","iopub.status.idle":"2023-09-24T00:44:22.832156Z","shell.execute_reply.started":"2023-09-24T00:44:19.953541Z","shell.execute_reply":"2023-09-24T00:44:22.831066Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"checkpoint = \"microsoft/DialoGPT-medium\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = AutoModelForCausalLM.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-09-24T00:44:27.215639Z","iopub.execute_input":"2023-09-24T00:44:27.216001Z","iopub.status.idle":"2023-09-24T00:44:36.767340Z","shell.execute_reply.started":"2023-09-24T00:44:27.215961Z","shell.execute_reply":"2023-09-24T00:44:36.766566Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class ChatBot():\n    def __init__(self):\n        self.chat_history_ids = None\n        self.bot_input_ids = None\n        self.end_chat = False\n        self.welcome()\n        \n    def welcome(self):\n        print(\"Initializing ChatBot ...\")\n        time.sleep(2)\n        print('Type \"bye\" or \"quit\" or \"exit\" to end chat \\n')\n        time.sleep(3)\n        greeting = np.random.choice([\n            \"Welcome, How are you?\",\n            \"Hey, Great day! I am your ChatBot\",\n            \"Hello, it's my pleasure meeting you\",\n            \"Hi, Let's chat!\"\n        ])\n        print(\"ChatBot >>  \" + greeting)\n        \n    def user_input(self):\n        text = input(\"User    >> \")\n        if text.lower().strip() in ['bye', 'quit', 'exit']:\n            self.end_chat=True\n            print('ChatBot >>  See you soon! Bye!')\n            time.sleep(1)\n            print('\\nQuitting ChatBot ...')\n        else:\n            self.new_user_input_ids = tokenizer.encode(text + tokenizer.eos_token, \\\n                                                       return_tensors='pt')\n\n    def bot_response(self):\n        if self.chat_history_ids is not None:\n            self.bot_input_ids = torch.cat([self.chat_history_ids, self.new_user_input_ids], dim=-1) \n        else:\n            self.bot_input_ids = self.new_user_input_ids\n        self.chat_history_ids = model.generate(self.bot_input_ids, max_length=1000, \\\n                                               pad_token_id=tokenizer.eos_token_id)\n            \n        response = tokenizer.decode(self.chat_history_ids[:, self.bot_input_ids.shape[-1]:][0], \\\n                               skip_special_tokens=True)\n        if response == \"\":\n            response = self.random_response()\n\n        print('ChatBot >>  '+ response)\n        \n\n    def random_response(self):\n        i = -1\n        response = tokenizer.decode(self.chat_history_ids[:, self.bot_input_ids.shape[i]:][0], \\\n                               skip_special_tokens=True)\n        while response == '':\n            i = i-1\n            response = tokenizer.decode(self.chat_history_ids[:, self.bot_input_ids.shape[i]:][0], \\\n                               skip_special_tokens=True)\n        if response.strip() == '?':\n            reply = np.random.choice([\"I don't know\", \n                                     \"I am not sure\"])\n        else:\n            reply = np.random.choice([\"Great\", \n                                      \"Fine. What's up?\", \n                                      \"Okay\"\n                                     ])\n        return reply","metadata":{"execution":{"iopub.status.busy":"2023-09-24T00:44:42.398387Z","iopub.execute_input":"2023-09-24T00:44:42.398750Z","iopub.status.idle":"2023-09-24T00:44:42.417256Z","shell.execute_reply.started":"2023-09-24T00:44:42.398710Z","shell.execute_reply":"2023-09-24T00:44:42.416211Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"bot = ChatBot()\nwhile True:\n    bot.user_input()\n    if bot.end_chat:\n        break\n    bot.bot_response()    ","metadata":{"execution":{"iopub.status.busy":"2023-09-24T00:44:48.019093Z","iopub.execute_input":"2023-09-24T00:44:48.019449Z","iopub.status.idle":"2023-09-24T00:46:00.390047Z","shell.execute_reply.started":"2023-09-24T00:44:48.019398Z","shell.execute_reply":"2023-09-24T00:46:00.389211Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Initializing ChatBot ...\nType \"bye\" or \"quit\" or \"exit\" to end chat \n\nChatBot >>  Hi, Let's chat!\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  hi How are you ?\n"},{"name":"stdout","text":"ChatBot >>  I'm good, how are you?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  i'm fine\n"},{"name":"stdout","text":"ChatBot >>  That's good.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  who created python?\n"},{"name":"stdout","text":"ChatBot >>  I did.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  are you a developer?\n"},{"name":"stdout","text":"ChatBot >>  I am.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  are you a software engnieer\n"},{"name":"stdout","text":"ChatBot >>  I am.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  bye\n"},{"name":"stdout","text":"ChatBot >>  See you soon! Bye!\n\nQuitting ChatBot ...\n","output_type":"stream"}]}]}